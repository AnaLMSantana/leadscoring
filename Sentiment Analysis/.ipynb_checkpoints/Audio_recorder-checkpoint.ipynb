{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import speech_recognition as sr\n",
    "import azure.cognitiveservices.speech as speechsdk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Recording\n",
      "Recording Done\n"
     ]
    }
   ],
   "source": [
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "\n",
    "p= pyaudio.PyAudio()\n",
    "stream=p.open(format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    frames_per_buffer=CHUNK)\n",
    "print(\"Start Recording\")\n",
    "\n",
    "frames=[]\n",
    "seconds=5\n",
    "for i in range(0,int(RATE/CHUNK*seconds)):\n",
    "    data=stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "    \n",
    "print(\"Recording Done\")\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf=wave.open('recording.wav','wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love your product.\n"
     ]
    }
   ],
   "source": [
    "def azure_transcribe(audio_path, subscription_key, region):\n",
    "    \n",
    "    # Set up the Azure Speech SDK\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=region)\n",
    "    audio_input = speechsdk.AudioConfig(filename=audio_path)\n",
    "\n",
    "    # Create a speech recognizer\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_input)\n",
    "\n",
    "    # Transcribe\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        return result.text\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        return \"No speech could be recognized\"\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        return \"Speech Recognition canceled: {}. Error details: {}\".format(cancellation_details.reason, cancellation_details.error_details)\n",
    "\n",
    "# Example usage\n",
    "transcription_result = azure_transcribe(\n",
    "    r\"C:\\Users\\Ana\\OneDrive\\Documents\\Ironhack\\Week 9\\Final Project\\Sentiment Analysis\\recording.wav\", \n",
    "    \"efb37ac3f0224c9eb9e58b588686a83f\", \n",
    "    \"eastus\"\n",
    ")\n",
    "\n",
    "print(transcription_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def azure_transcribe(subscription_key, region, record_seconds=5):\n",
    "    # Audio Recording\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 44100\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "    print(\"Start Recording...\")\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * record_seconds)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Recording Done!\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open('recording.wav', 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    # Azure Transcription\n",
    "    audio_path = 'recording.wav'\n",
    "\n",
    "    # Set up the Azure Speech SDK\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=region)\n",
    "    audio_input = speechsdk.AudioConfig(filename=audio_path)\n",
    "\n",
    "    # Create a speech recognizer\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_input)\n",
    "\n",
    "    # Transcribe\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        return result.text\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        return \"No speech could be recognized\"\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        return \"Speech Recognition canceled: {}. Error details: {}\".format(cancellation_details.reason, cancellation_details.error_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Recording\n",
      "Recording Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I didn't like your service.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azure_transcribe('efb37ac3f0224c9eb9e58b588686a83f','eastus', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m MODEL\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcardiffnlp/twitter-roberta-base-sentiment\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(MODEL)\n\u001b[1;32m----> 6\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSequenceClassification\u001b[39m.\u001b[39;49mfrom_pretrained(MODEL)\n",
      "File \u001b[1;32mc:\\Users\\Ana\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py:1070\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_from_config\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1069\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1070\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[1;32mc:\\Users\\Ana\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py:1049\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[39m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_available() \u001b[39mand\u001b[39;00m is_tf_available():\n\u001b[1;32m-> 1049\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001b[39m.\u001b[39mformat(name))\n\u001b[0;32m   1051\u001b[0m \u001b[39m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m is_torch_available() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tf_available():\n",
      "\u001b[1;31mImportError\u001b[0m: \nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "MODEL= \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_scores(sentence):\n",
    "    MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "    \n",
    "    encoded_text = tokenizer(sentence, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    scores_dict = {\n",
    "        'roberta_neg': scores[0],\n",
    "        'roberta_neu': scores[1],\n",
    "        'roberta_pos': scores[2]\n",
    "    }\n",
    "    \n",
    "    if scores_dict['roberta_neg'] > 0.8:\n",
    "        sentiment_label = \"Very bad\"\n",
    "    elif scores_dict['roberta_neg'] > scores_dict['roberta_pos']:\n",
    "        sentiment_label = \"Bad\"\n",
    "    elif scores_dict['roberta_neu'] > scores_dict['roberta_pos'] and scores_dict['roberta_neu'] > scores_dict['roberta_neg']:\n",
    "        sentiment_label = \"Neutral\"\n",
    "    elif scores_dict['roberta_pos'] > 0.8:\n",
    "        sentiment_label = \"Very good\"\n",
    "    else:\n",
    "        sentiment_label = \"Good\"\n",
    "    \n",
    "    scores_dict['sentiment_label'] = sentiment_label\n",
    "    \n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta_neg': 0.972369,\n",
       " 'roberta_neu': 0.025089052,\n",
       " 'roberta_pos': 0.0025419325,\n",
       " 'sentiment_label': 'Very bad'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sentiment_scores(\"I didn't like your service.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9972062706947327}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence= \"I didn't like your service.\"\n",
    "sent_pipeline = pipeline(\"sentiment-analysis\")\n",
    "sent_pipeline(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "def azure_transcribe(subscription_key, region, record_seconds=5):\n",
    "    # Audio Recording\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 44100\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "    print(\"Start Recording\")\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * record_seconds)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Recording Done\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open('recording.wav', 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    # Azure Transcription\n",
    "    audio_path = 'recording.wav'\n",
    "\n",
    "    # Set up the Azure Speech SDK\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=region)\n",
    "    audio_input = speechsdk.AudioConfig(filename=audio_path)\n",
    "\n",
    "    # Create a speech recognizer\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_input)\n",
    "\n",
    "    # Transcribe\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        return result.text\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        return \"No speech could be recognized\"\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        return \"Speech Recognition canceled: {}. Error details: {}\".format(cancellation_details.reason, cancellation_details.error_details)\n",
    "\n",
    "def analyze_sentiment_scores(subscription_key, region, record_seconds=5):\n",
    "    # Step 1: Record and transcribe the audio\n",
    "    transcription = azure_transcribe(subscription_key, region, record_seconds)\n",
    "    \n",
    "    # Step 2: Perform sentiment analysis on the transcription\n",
    "    MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "    \n",
    "    encoded_text = tokenizer(transcription, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    scores_dict = {\n",
    "        'roberta_neg': scores[0],\n",
    "        'roberta_neu': scores[1],\n",
    "        'roberta_pos': scores[2]\n",
    "    }\n",
    "    \n",
    "    if scores_dict['roberta_neg'] > 0.8:\n",
    "        sentiment_label = \"Very bad\"\n",
    "    elif scores_dict['roberta_neg'] > scores_dict['roberta_pos']:\n",
    "        sentiment_label = \"Bad\"\n",
    "    elif scores_dict['roberta_neu'] > scores_dict['roberta_pos'] and scores_dict['roberta_neu'] > scores_dict['roberta_neg']:\n",
    "        sentiment_label = \"Neutral\"\n",
    "    elif scores_dict['roberta_pos'] > 0.8:\n",
    "        sentiment_label = \"Very good\"\n",
    "    else:\n",
    "        sentiment_label = \"Good\"\n",
    "    \n",
    "    result_string = f\"Transcription of the recorded text: {transcription}\\nSentiment: {sentiment_label}\"\n",
    "    \n",
    "    return result_string\n",
    "\n",
    "# Usage example:\n",
    "# subscription_key = \"YOUR_AZURE_SUBSCRIPTION_KEY\"\n",
    "# region = \"YOUR_AZURE_REGION\"\n",
    "# result = analyze_sentiment_scores(subscription_key, region)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Recording\n",
      "Recording Done\n",
      "Transcription of the recorded text: You have a nice product. Thank you.\n",
      "Sentiment: Very good\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "# subscription_key = \"YOUR_AZURE_SUBSCRIPTION_KEY\"\n",
    "# region = \"YOUR_AZURE_REGION\"\n",
    "result = analyze_sentiment_scores('efb37ac3f0224c9eb9e58b588686a83f','eastus')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle to save my funtion \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pickle with the whole funtion\n",
    "with open('analyze_sentiment_scores.pkl', 'wb') as f:\n",
    "    pickle.dump(analyze_sentiment_scores,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('analyze_sentiment_scores.pkl', 'rb') as f:\n",
    "#     analyze_sentiment_scores_unpickled = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
